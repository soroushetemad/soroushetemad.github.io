<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0, minimum-scale=1.0" />
    <title>Soroush Etemad</title>
    
    <link rel="stylesheet" href="style.css">
    
    <link rel="icon" href="images/face.png" type="image/png" />
</head>
<body>

    <div class="cursor" id="cursor"></div>

    <div id="preloader">
        <img src="images/profile.jpg" alt="Soroush Etemad" class="preloader-profile-pic"/>
    </div>

    <canvas id="neuralCanvas"></canvas>

    <nav>
        <a href="javascript:void(0)" onclick="scrollToSection('home')" class="logo"></a>
        <button class="hamburger" id="hamburger-button">
            <span></span>
            <span></span>
            <span></span>
        </button>
        <ul class="nav-menu" id="nav-menu">
            <li><a onclick="scrollToSection('about')" class="nav-link">About</a></li>
            <li><a onclick="scrollToSection('experience')" class="nav-link">Experience</a></li>
            <li><a onclick="scrollToSection('projects')" class="nav-link">Projects</a></li>
            <!-- <li><a onclick="scrollToSection('blog')" class="nav-link">Blog</a></li>
            <li><a onclick="scrollToSection('contact')" class="nav-link">Contact</a></li> -->
            <li><a href="https://drive.google.com/file/d/1FGxxIIKuOM638fUL1uNYU69qrFGEq8wL/view?usp=sharing" target="_blank" rel="noopener noreferrer" class="button-resume">Resume</a></li>

        </ul>
    </nav>
    
    <main>
        <section id="home">
            <div class="hero-layout">
                <div class="hero-content">
                    <!-- <p class="hero-intro">Hi, my name is</p> -->
                    <h1 class="hero-name">Soroush Etemad</h1>
                    <h2 class="hero-tagline">Robotics & AI</h2>
                    <a href="mailto:setemad.dev@gmail.com" class="button-primary">Get In Touch</a>
                </div>
                <div class="hero-image-container">
                    <img src="images/profile.jpg" alt="Soroush Etemad" class="profile-pic"/>
                </div>
            </div>
        </section>

        <section id="about">
            <h2 class="section-heading">About Me</h2>
            <div class="about-content">
                <div class="about-text">
                        <style>
                            /* Improve spacing between paragraphs in About Me section */
                            .about-text p {
                                margin-bottom: 1.3em;
                            }
                            .about-text ul.skills-list {
                                margin-top: 1.3em;
                            }
                        </style>
                    <!-- <p>
                        <strong>Welcome to my page!</strong>
                    </p> -->
                    <p>
                        I am a robotics and mechanical engineer with a focus in physical AI.
                    </p>
                    <p>
                        With over two years of industry experience in hardware design and software engineering, I bring a versatile, multidisciplinary skillset that seamlessly integrates advanced technology with innovative problem-solving. My interests include computer vision, reinforcement learning, tactile sensing, natural language processing, and product design.
                    </p>
                    <p>
                        Outside of work, I enjoy photography, hiking, running, paddleboarding, and cooking. I enjoy staying engaged with the latest AI research advancements and industry trends. I channel my creativity into personal side projects, experimenting and prototyping new ideas.
                    </p>
                    <!-- <p>Here are a few technologies I’ve been working with recently:</p> -->
                    <!-- <ul class="skills-list">
                        <li>Python</li>
                        <li>C++</li>
                        <li>ROS2</li>
                        <li>TensorFlow</li>
                        <li>PyTorch </li>
                        <li>SQL</li>
                    </ul> -->
                </div>
                <div class="education-section">
                    <h3 class="about-subheading">Education</h3>
                    <div class="edu-timeline">
                        <div class="edu-block">
                            <div class="edu-header">
                                <img src="images/umd_logo.png" alt="University Logo" class="edu-logo">
                                <div class="edu-header-text">
                                   <h4 class="edu-degree">M.Eng in Robotics</h4>
                                   <p class="edu-school">University of Maryland, College Park</p>
                                </div>
                            </div>
                            <p class="edu-dates">Aug 2023 – May 2025</p>
                            <p class="edu-courses"><strong>Relevant Courses:</strong> Robot Learning, Deep Learning and AI, Computer Vision, Path Planning, Robot Modeling, Human Robot Interaction, Control System, Software Product Management.</p>
                        </div> 
                        <div class="edu-block">
                            <div class="edu-header">
                                <img src="images/umd_logo.png" alt="University Logo" class="edu-logo">
                                 <div class="edu-header-text">
                                    <h4 class="edu-degree">B.S in Mechanical Engineering</h4>
                                    <p class="edu-school">University of Maryland, College Park</p>
                                </div>
                            </div>
                            <p class="edu-dates">Aug 2019 – May 2023</p>
                            <p class="edu-courses"><strong>Relevant Courses:</strong> Object Oriented Programming, Remote Sensing, Assistive Robotics, Automotive Design, Dynamics, Discrete Structures, Computer Aided Design (CAD).</p>
                        </div>
                    </div>
                </div>
            </div>
        </section>

    <section id="experience">
    <h2 class="section-heading">Where I've Worked</h2>

    <div class="experience-item">
        <h3>
        <span class="exp-title">Systems Engineer</span>
        <span class="exp-company">@ Booz Allen Hamilton</span>
        </h3>
        <p class="exp-dates">Jul 2023 – Present | McLean, VA</p>
        <ul class="exp-duties">
                <li><span class="custom-bullet"></span>Virtual Space Ground System (VSGS): Developed and deployed a self-hosted AI assistant using a RAG pipeline over satellite mission data to enhance user experience; delivered live demos to 250+ stakeholders, securing adoption by client teams.</li>
                <li><span class="custom-bullet"></span>Deployed microservices and optimized API/data flows, improving modularity and interoperability of mission platforms.</li>
                <li><span class="custom-bullet"></span>Partnered with a drone startup to integrate ATAK and TAK Server into their FPV UAS platform, enabling real-time telemetry and video to enhance warfighter situational awareness and operational effectiveness.</li>
                <li><span class="custom-bullet"></span>Shaped multi-million dollar Army robotics programs by co-authoring whitepapers and translating customer requirements into system design and innovative technical solutions; collaborated with external stakeholders to incorporate their capabilities into comprehensive solutions and respond to DoD RFIs and RFPs.</li>
                <li><span class="custom-bullet"></span>Demonstrated Boston Dynamics Spot and Ghost Robotics Vision 60 quadruped robotic platforms at major internal and external conferences/trade shows, highlighting the companies human-machine teaming capabilities</li>
        </ul>
    </div>

    <div class="experience-item">
        <h3>
        <span class="exp-title">Graduate Robotics Research Assistant</span>
        <span class="exp-company">@ Perception Robotics Group</span>
        </h3>
        <p class="exp-dates">Dec 2024 – Present | College Park, MD</p>
        <ul class="exp-duties">
                <li><span class="custom-bullet"></span>Conducting research on tactile-based manipulation with behavior cloning under Prof. Yiannis Aloimonos.</li>
                <li><span class="custom-bullet"></span>Developed a handheld data collection tool with custom grippers for imitation learning experiments.</li>
                <li><span class="custom-bullet"></span>Designed and built a handheld data collection gripper with integrated tactile sensors for in-the-wild dexterous robot manipulation experiments.</li>
                <li><span class="custom-bullet"></span>Collected multi-modal training data (tactile, visual, proprioceptive), augmented data to improve dataset robustness, trained diffusion policy neural network, and deployed validated model on UR5e robot arm.</li>
        </ul>
    </div>

    <div class="experience-item">
        <h3>
        <span class="exp-title">Mechanical Engineering Intern</span>
        <span class="exp-company">@ U.S. Nuclear Regulatory Commission (NRC)</span>
        </h3>
        <p class="exp-dates">May 2022 – Aug 2022 | College Park, MD</p>
        <ul class="exp-duties">
                <li><span class="custom-bullet"></span>Simulated boric and pure water mixing in NuScale SMRs using Nek5000 CFD software to analyze safety-critical jet flows during accident scenarios.</li>
                <li><span class="custom-bullet"></span>Produced detailed visualizations and presented results to the Code and Reactor Analysis Branch.</li>
        </ul>
    </div>
    <style>
    /* Custom bullet styling for experience duties, similar to education section */
    .custom-bullets {
        list-style: none;
        padding-left: 0;
    }
    .custom-bullet {
        display: inline-block;
        width: 8px;
        height: 8px;
        margin-right: 12px;
        border-radius: 50%;
        background: var(--accent-primary, #6C63FF);
        vertical-align: middle;
        box-shadow: 0 0 2px rgba(0,0,0,0.08);
    }
    .exp-duties li {
        margin-bottom: 8px;
        font-size: 1rem;
        line-height: 1.6;
        position: relative;
    }
    </style>
    </section>

        <!-- <section id="experience">
            <h2 class="section-heading">Where I've Worked</h2>
            <div class="experience-item"><h3><span class="exp-title">Systems Engineer</span> <span class="exp-company">@ Booz Allen</span></h3><p class="exp-dates">2023 - Present</p><ul class="exp-duties"><li>Virtual Space Ground System (VSGS): Built a self-hosted AI assistant for on-prem LLM inference using a RAG pipeline over satellite mission data, with memory and reusable architecture later adopted by client teams; deployed microservices, API integration, and data flow optimization improving platform modularity and interoperability.</li><li>Partnered with a drone startup to integrate ATAK and TAK Server into their FPV UAS platform, enabling real-time telemetry and video to enhance warfighter situational awareness and operational effectiveness.</li><li>Shaped Army robotics program proposal by co-authoring whitepaper and translating customer requirements into system design and technical solution; informed market research and guided proposal response.</li></ul></div>
            <div class="experience-item"><h3><span class="exp-title">Research Scientist</span> <span class="exp-company">@ Advanced Robotics Institute</span></h3><p class="exp-dates">2018 - 2020</p><ul class="exp-duties"><li>Conducted groundbreaking research in human-robot interaction and autonomous navigation systems.</li><li>Published 12 peer-reviewed papers and secured $1.5M in research funding.</li><li>Developed novel algorithms for real-time sensor fusion and decision-making in complex environments.</li></ul></div>
            <div class="experience-item"><h3><span class="exp-title">Robotics Engineer</span> <span class="exp-company">@ TechnoBot Solutions</span></h3><p class="exp-dates">2016 - 2018</p><ul class="exp-duties"><li>Designed and programmed autonomous mobile robots for industrial applications.</li><li>Implemented machine learning algorithms for object recognition and path planning.</li></ul></div>
        </section> -->

        <section id="projects">
            <h2 class="section-heading">Some Things I've Built</h2>
            
            <ul class="project-list">
                <li class="project-item">
                    <div class="project-content">
                        <div>
                            <p class="project-overline">Featured Project</p>
                            <h3 class="project-title">Touch 3D</h3>
                            <div class="project-description">
                                <p> Developed a reinforcement learning pipeline that uses a simulated DIGIT tactile sensor to actively explore and reconstruct 3D object surfaces. The system learns efficient exploration policies with PPO, fuses tactile depth maps into point clouds, and generalizes from simple shapes to unseen YCB objects with up to 95% coverage.</p>
                            </div>
                            <ul class="project-tech-list">
                                <li>Python</li>
                                <li>Pybullet</li>
                                <li>StableBaseline3</li>
                                <li>OpenAI Gym</li>
                            </ul>
                            <div class="project-links">
                                <a href="https://github.com/soroushetemad/Touch3D.git" aria-label="GitHub Link" target="_blank" rel="noopener noreferrer">
                                    <svg xmlns="http://www.w3.org/2000/svg" role="img" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-github"><title>GitHub</title><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22"></path></svg>
                                </a>
                                <a href="https://drive.google.com/file/d/1xuZfrK8E2y9OMAfJyR_XCIeGWc7qu1Cu/view?usp=sharing" aria-label="Research Paper" target="_blank" rel="noopener noreferrer">
                                    <svg xmlns="http://www.w3.org/2000/svg" role="img" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file-text"><title>Research Paper</title><path d="M14 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V8z"/><polyline points="14 2 14 8 20 8"/><line x1="16" y1="13" x2="8" y2="13"/><line x1="16" y1="17" x2="8" y2="17"/><polyline points="10 9 9 9 8 9"/></svg>
                                </a>
                                    <a href="https://docs.google.com/presentation/d/1hikx7oYXZ1x8A5XVNJZ4YiRiFnn7B6opOKa5jvDznEE/edit?usp=sharing" aria-label="Presentation" target="_blank" rel="noopener noreferrer">
                                        <svg xmlns="http://www.w3.org/2000/svg" role="img" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-slides"><title>Presentation</title><rect x="3" y="4" width="18" height="12" rx="2" ry="2"/><path d="M8 20h8"/><path d="M12 16v4"/></svg>
                                    </a>
                            </div>
                        </div>
                    </div>
                    <div class="project-image">
                        <img src="images/touch3d1.gif" alt="Training policy in simulation">
                    </div>
                </li>



                <li class="project-item">
                    <div class="project-content">
                        <div>
                            <!-- <p class="project-overline">Featured Project</p> -->
                            <h3 class="project-title">TransUNet based Autonomous Scene Segmentation</h3>
                            <div class="project-description">
                                <p> We implemented and benchmarked UNet, TransUNet, and Swin-UNet for semantic segmentation on the KITTI dataset. The pipeline included data preprocessing, augmentation, and class-balanced training with AdamW optimization and combined Dice + cross-entropy loss. Results showed that UNet achieved the highest Dice score (0.885), while Swin-UNet delivered the best mean IoU (0.7912) and fastest inference (26 ms), excelling at distant-object and depth-sensitive segmentation. This work highlights the trade-offs between CNNs and Transformer-based models for real-world autonomous driving perception..</p>
                            </div>
                            <ul class="project-tech-list">
                                <li>Python</li>
                                <li>ViT</li>
                                <li>Transformer</li>
                                <li>KITTI Dataset</li>
                            </ul>
                            <div class="project-links">
                                <a href="https://github.com/soroushetemad/TransUNet-based-Autonomous-Scene-Segmentation.git" aria-label="GitHub Link" target="_blank" rel="noopener noreferrer">
                                    <svg xmlns="http://www.w3.org/2000/svg" role="img" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-github"><title>GitHub</title><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22"></path></svg>
                                </a>
                                <!-- <a href="https://drive.google.com/file/d/1xuZfrK8E2y9OMAfJyR_XCIeGWc7qu1Cu/view?usp=sharing" aria-label="Research Paper" target="_blank" rel="noopener noreferrer">
                                    <svg xmlns="http://www.w3.org/2000/svg" role="img" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file-text"><title>Research Paper</title><path d="M14 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V8z"/><polyline points="14 2 14 8 20 8"/><line x1="16" y1="13" x2="8" y2="13"/><line x1="16" y1="17" x2="8" y2="17"/><polyline points="10 9 9 9 8 9"/></svg>
                                </a>
                                    <a href="https://docs.google.com/presentation/d/1hikx7oYXZ1x8A5XVNJZ4YiRiFnn7B6opOKa5jvDznEE/edit?usp=sharing" aria-label="Presentation" target="_blank" rel="noopener noreferrer">
                                        <svg xmlns="http://www.w3.org/2000/svg" role="img" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-slides"><title>Presentation</title><rect x="3" y="4" width="18" height="12" rx="2" ry="2"/><path d="M8 20h8"/><path d="M12 16v4"/></svg>
                                    </a> -->
                            </div>
                        </div>
                    </div>
                    <div class="project-image">
                        <img src="images/swin.png" alt="Test comparison">
                    </div>
                </li>

            <li class="project-item">
            <div class="project-content">
                <div>
                <h3 class="project-title">Shower Fall Detection Device</h3>
                <div class="project-description">
                <p>
                Developed an AI-enabled shower fall detection system that runs on a Raspberry Pi with a custom mechanical design. Collected and annotated a dataset from intentionally blurred videos of simulated falls, then fine-tuned an YOLOv8 object detection model to classify standing, bending, and falling stages in real time directly on-device. When a fall is detected, the system automatically shuts off water to prevent drowning or further injury and alerts emergency contacts. This innovation enhances safety in high-risk environments, earned the Linda Schmidt Innovation Award, and resulted in a U.S. patent
                <a href="https://patents.google.com/patent/US20240411290A1" target="_blank" rel="noopener noreferrer" class="highlight-link">
                 (US-20240411290-A1)</a>
                </p>

                <!-- <p>
                Develop a AI-enabled fall detection system for showers, integrating
                <strong>YOLOv8</strong> object detection with a <strong>Raspberry Pi</strong> and custom mechanical design.
                Collected and annotated a custom dataset using physically blurred videos of humans falling in the shower. Fine-tuned <strong>YOLOv8</strong> model to classify standing, bending and falling stages in real-time directly on the device from blurred input. When a fall is detected, the water automatically shuts off to prevent drowning or further injury and alerts emergency contacts. This device improves safety in high-risk environments, earned the Linda Schmidt Innovation Award, and resulted in a published U.S. patent
                <a href="https://patents.google.com/patent/US20240411290A1" target="_blank" rel="noopener noreferrer" class="highlight-link">
                 (US-20240411290-A1)</a>
                </p> -->
                </div>
                <ul class="project-tech-list">
                    <li>OpenCV</li>
                    <li>YOLOv8</li>
                    <li>Mechanical Design</li>
                    <li>Raspberry Pi</li>
                </ul>
                <!-- <div class="project-links">
                    <a href="#" aria-label="GitHub Link" target="_blank" rel="noopener noreferrer">
                    <svg xmlns="http://www.w3.org/2000/svg" role="img" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-github">
                        <title>GitHub</title>
                        <path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22"></path>
                    </svg>
                    </a>
                </div> -->
                </div>
            </div>
            <div class="project-image">
                <img src="images/capstone.gif" alt="Fall detection result">
                <!-- <img src="images/face.png" alt="Prototype hardware" style="margin-top:10px;"> -->

            </div>

            <li class="project-item">
                <div class="project-content">
                    <div>
                        <!-- <p class="project-overline">Featured Project</p> -->
                        <h3 class="project-title">A* Path Planning TurtleBot3</h3>
                        <div class="project-description">
                            <p> This project focuses on the implementation of the A* algorithm for path planning on a TurtleBot3 Waffle robot navigating through a predefined obstacle space. The A* algorithm is a widely used method for finding the shortest path between nodes in a graph, making it suitable for navigation tasks. In this demo, the user specifies a target coordinate location and the robot plans the path and then navigates to the point and then stops.</p>
                        </div>
                        <ul class="project-tech-list">
                            <li>Python</li>
                            <li>ROS2</li>
                            <li>Gazebo</li>
                            <li>A* algorithm</li>
                        </ul>
                        <div class="project-links">
                            <a href="https://github.com/soroushetemad/A_Star_PathPlanning.git" aria-label="GitHub Link" target="_blank" rel="noopener noreferrer">
                                <svg xmlns="http://www.w3.org/2000/svg" role="img" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-github"><title>GitHub</title><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22"></path></svg>
                            </a>
                            
                        </div>
                    </div>
                </div>
                <div class="project-image">
                    <img src="images/astar.gif" alt="Training policy in simulation">
                </div>
            </li>

          <li class="project-item">
                <div class="project-content">
                    <div>
                        <!-- <p class="project-overline">Featured Project</p> -->
                        <h3 class="project-title">RRT* Dynamic Path Planning </h3>
                        <div class="project-description">
                            <p> This project implements the RRT* (Rapidly-Exploring Random Tree Star) algorithm, a sampling-based motion planning method that incrementally grows a tree in the configuration space to find an optimal path. The algorithm samples random points, extends the tree toward them while avoiding obstacles, and selects the lowest-cost connections to refine the path. Through rewiring and pruning, it improves efficiency and ensures convergence toward an optimal solution. In this demo, the user continuously adds new obstacles in the space, requiring the algorithm to dynamically replan and compute a new collision-free path from the start to the goal.</p>
                        </div>
                        <ul class="project-tech-list">
                            <li>Python</li>
                            <li>pygame</li>
                            <li>RRT* algorithm</li>
                        </ul>
                        <div class="project-links">
                            <a href="https://github.com/soroushetemad/RRTStar_Dynamic_Environment-.git" aria-label="GitHub Link" target="_blank" rel="noopener noreferrer">
                                <svg xmlns="http://www.w3.org/2000/svg" role="img" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-github"><title>GitHub</title><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22"></path></svg>
                            </a>
                            <a href="https://drive.google.com/file/d/1D8rKp5PnpGI0uCcamLLDiqFSJuBeTOkd/view?usp=sharing" aria-label="Research Paper" target="_blank" rel="noopener noreferrer">
                                <svg xmlns="http://www.w3.org/2000/svg" role="img" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file-text"><title>Research Paper</title><path d="M14 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V8z"/><polyline points="14 2 14 8 20 8"/><line x1="16" y1="13" x2="8" y2="13"/><line x1="16" y1="17" x2="8" y2="17"/><polyline points="10 9 9 9 8 9"/></svg>
                            </a>
                            
                        </div>
                    </div>
                </div>
                <div class="project-image">
                    <img src="images/rrtstar.gif" alt="Training policy in simulation" style="width: 90%;">
                </div>
            </li>

            


            </li>
            </ul>
        <!-- </section>
        <section id="blog">
            <h2 class="section-heading">From My Blog</h2>
            <ul class="blog-list">
                <li class="blog-item">
                    <div class="blog-header">
                        <div class="blog-header-text">
                            <p class="blog-date">June 07, 2025</p>
                            <h3 class="blog-title">The Intersection of AI and Robotics</h3>
                        </div>
                        <button class="blog-toggle-button">+</button>
                    </div>
                    <div class="blog-details-wrapper">
                        <div class="blog-content">
                            <p>Exploring the symbiotic relationship between Artificial Intelligence and Robotics. AI provides the 'brain' for robots, enabling them to perceive, learn, and make decisions. This post delves into the latest advancements and the future trajectory of intelligent machines...</p>
                            <a href="#" class="read-more-link">Read More &rarr;</a>
                        </div>
                    </div>
                </li>
                <li class="blog-item">
                    <div class="blog-header">
                        <div class="blog-header-text">
                            <p class="blog-date">May 22, 2025</p>
                            <h3 class="blog-title">A Deep Dive into Reinforcement Learning</h3>
                        </div>
                        <button class="blog-toggle-button">+</button>
                    </div>
                    <div class="blog-details-wrapper">
                        <div class="blog-content">
                             <p>Reinforcement Learning (RL) is a powerful paradigm for training autonomous agents. Unlike supervised learning, RL agents learn from trial and error, guided by a reward signal. This article breaks down the core concepts of RL, including Q-learning, Policy Gradients, and their application in robotics...</p>
                             <a href="#" class="read-more-link">Read More &rarr;</a>
                        </div>
                    </div>
                </li>
            </ul>
        </section>

        
            <section id="contact">
                <h2 class="section-heading">What's Next?</h2>
                <h3 class="contact-title">Get In Touch</h3>
                <p class="contact-text">
                    I am currently seeking new opportunities and welcome any chance to connect. Whether you have a specific role in mind, a question about my work, or just want to discuss the future of robotics, my inbox is always open. I'll be sure to get back to you promptly!
                </p>
                <a href="mailto:skadoosh2710@gmail.com?subject=Opportunity%20from%20Your%20Portfolio" class="button-primary">Say Hello</a>

                <div class="social-links">
                    <h4>Connect with me on other platforms:</h4>
                    <ul>
                        <li><a href="#" target="_blank" rel="noopener noreferrer">GitHub</a></li>
                        <li><a href="#" target="_blank" rel="noopener noreferrer">LinkedIn</a></li>
                        </ul>
                </div>
            </section>
    </main> -->

    <footer>
        <div>
            Designed & Built by Soroush Etemad
        </div>
    </footer>

    <script>
        /* --------------------------- */
        /* CUSTOM CURSOR LOGIC    */
        /* --------------------------- */
        const cursor = document.getElementById('cursor');
        if (cursor) {
            document.addEventListener('mousemove', (e) => {
                if (window.innerWidth > 768) { // Only show cursor on desktop
                    cursor.style.left = e.clientX + 'px';
                    cursor.style.top = e.clientY + 'px';
                }
            });
        }
        /* --------------------------- */
        /* PRELOADER LOGIC             */
        /* --------------------------- */
        window.addEventListener('load', () => {
            const preloader = document.getElementById('preloader');
            const mainContent = document.querySelector('main');
            const img = preloader.querySelector('.preloader-profile-pic');
            
            // Hide main content initially
            mainContent.style.display = 'none';
            
            // Add loading spinner
            const spinner = document.createElement('div');
            spinner.classList.add('loading-spinner');
            preloader.insertBefore(spinner, img);
            
            setTimeout(() => {
                preloader.classList.add('hidden');
                // Show main content after preloader is hidden
                mainContent.style.display = 'block';
                mainContent.style.animation = 'fadeIn 0.5s ease-in';
            }, 1200);
        });

        // Add CSS for spinner and fade animations
        const style = document.createElement('style');
        style.textContent = `
            .loading-spinner {
            position: absolute;
            width: 150px;
            height: 150px;
            border: 3px solid transparent;
            border-top: 3px solid var(--accent-primary);
            border-radius: 50%;
            animation: spin 1s linear infinite;
            }
            
            @keyframes spin {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
            }
            
            @keyframes fadeIn {
            from { opacity: 0; }
            to { opacity: 1; }
            }
            
            #preloader {
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background: var(--bg-primary);
            display: flex;
            justify-content: center;
            align-items: center;
            z-index: 1000;
            }
            
            .preloader-profile-pic {
            width: 140px;
            height: 140px;
            border-radius: 50%;
            object-fit: cover;
            }

            #preloader.hidden {
            display: none;
            }
        `;
        document.head.appendChild(style);

        /* --------------------------- */
        /* MOBILE NAV & SCROLL LOGIC   */
        /* --------------------------- */
        const hamburgerButton = document.getElementById('hamburger-button');
        const navMenu = document.getElementById('nav-menu');
        const navLinks = document.querySelectorAll('#nav-menu a');
        const body = document.body;

        hamburgerButton.addEventListener('click', () => {
            hamburgerButton.classList.toggle('active');
            navMenu.classList.toggle('active');
            body.classList.toggle('blur');
        });
        
        navLinks.forEach(link => {
            link.addEventListener('click', () => {
                if (hamburgerButton.classList.contains('active')) {
                    hamburgerButton.classList.remove('active');
                    navMenu.classList.remove('active');
                    body.classList.remove('blur');
                }
            });
        });

        function scrollToSection(sectionId) {
            const section = document.getElementById(sectionId);
            if (section) {
                section.scrollIntoView({ behavior: 'smooth', block: 'start' });
            }
        }

        /* --------------------------- */
        /* EXPANDABLE BLOG POSTS       */
        /* --------------------------- */
        function toggleBlogItem(blogItem) {
            const button = blogItem.querySelector('.blog-toggle-button');
            blogItem.classList.toggle('expanded');
            button.textContent = blogItem.classList.contains('expanded') ? '−' : '+';
        }

        document.querySelectorAll('.blog-header').forEach(header => {
            header.addEventListener('click', () => {
                toggleBlogItem(header.closest('.blog-item'));
            });
        });

        /* --------------------------- */
        /* EXPANDABLE PROJECTS         */
        /* --------------------------- */
        document.querySelectorAll('.project-toggle-button').forEach(button => {
            button.addEventListener('click', () => {
                const projectItem = button.closest('.project-item');
                projectItem.classList.toggle('expanded');
                if (projectItem.classList.contains('expanded')) {
                    button.textContent = '−';
                } else {
                    button.textContent = '+';
                }
            });
        });

        /* ---------------------------------- */
        /* CANVAS & SCROLL-BASED VISIBILITY */
        /* ---------------------------------- */
        const canvas = document.getElementById('neuralCanvas');
        const homeSection = document.getElementById('home');

        const observer = new IntersectionObserver((entries) => {
            entries.forEach(entry => {
                // If home section is intersecting (visible), show canvas. Otherwise, hide it.
                if (entry.isIntersecting) {
                    canvas.classList.remove('hidden');
                } else {
                    canvas.classList.add('hidden');
                }
            });
        }, { threshold: 0.1 }); // Trigger when 10% of the hero is visible/hidden

        observer.observe(homeSection);

        
        /* --------------------------- */
        /* NEURAL NETWORK CANVAS       */
        /* --------------------------- */
        const ctx = canvas.getContext('2d');
        let nodes = [], connections = [], activePulses = [];

        class Node {
            constructor(x, y, layer) {
                this.x = x; this.y = y; this.layer = layer;
                this.baseRadius = Math.random() * 2 + 2;
                this.isFiring = false; this.fireIntensity = 0;
                this.charge = 0; this.activationThreshold = 0.7;
            }
            fire() {
                if (this.isFiring) return;
                this.isFiring = true; this.fireIntensity = 1;
                setTimeout(() => {
                    connections.forEach(conn => {
                        if (conn.a === this && conn.b.layer > this.layer) {
                           activePulses.push(new NeuralPulse(conn.a, conn.b));
                        }
                    });
                }, 50);
            }
            update() {
                if (this.isFiring) {
                    this.fireIntensity -= 0.02;
                    if (this.fireIntensity <= 0) this.isFiring = false;
                }
                this.charge *= 0.95;
                if (this.charge > this.activationThreshold && !this.isFiring) {
                    this.fire(); this.charge = 0;
                }
            }
            draw() {
                let alpha = 0.7, r = this.baseRadius, color;
                switch(this.layer) {
                    case 0: color = getComputedStyle(document.documentElement).getPropertyValue('--accent-primary'); break;
                    case 2: color = getComputedStyle(document.documentElement).getPropertyValue('--accent-secondary'); break;
                    default: color = getComputedStyle(document.documentElement).getPropertyValue('--text-secondary'); break;
                }
                if (this.isFiring) {
                    alpha = Math.max(alpha, this.fireIntensity);
                    r = this.baseRadius * (1 + this.fireIntensity);
                    color = getComputedStyle(document.documentElement).getPropertyValue('--neuron-fire-color');
                }
                const tempDiv = document.createElement('div');
                tempDiv.style.color = color;
                document.body.appendChild(tempDiv);
                const rgbColor = window.getComputedStyle(tempDiv).color;
                document.body.removeChild(tempDiv);
                ctx.beginPath();
                ctx.arc(this.x, this.y, r, 0, Math.PI * 2);
                ctx.fillStyle = rgbColor.replace(')', `, ${alpha})`).replace('rgb', 'rgba');
                ctx.fill();
                if (this.isFiring) {
                    const glowColor = rgbColor.replace(')', `, ${this.fireIntensity * 0.2})`).replace('rgb', 'rgba');
                    ctx.beginPath();
                    ctx.arc(this.x, this.y, r * 2.5, 0, Math.PI * 2);
                    ctx.fillStyle = glowColor;
                    ctx.fill();
                }
            }
        }
        class Connection {
            constructor(a, b) { this.a = a; this.b = b; this.activeIntensity = 0; }
            update() { if (this.activeIntensity > 0) this.activeIntensity -= 0.03; }
            draw() {
                let alpha = 0.15 + this.activeIntensity * 0.6;
                let color = this.activeIntensity > 0 ? 'var(--neuron-fire-color)' : 'var(--text-primary)';
                const tempDiv = document.createElement('div');
                tempDiv.style.color = getComputedStyle(document.documentElement).getPropertyValue(color.substring(4, color.length-1));
                document.body.appendChild(tempDiv);
                const rgbColor = window.getComputedStyle(tempDiv).color;
                document.body.removeChild(tempDiv);
                ctx.beginPath();
                ctx.moveTo(this.a.x, this.a.y);
                ctx.lineTo(this.b.x, this.b.y);
                ctx.strokeStyle = rgbColor.replace(')', `, ${alpha})`).replace('rgb', 'rgba');
                ctx.lineWidth = 1 + this.activeIntensity;
                ctx.stroke();
            }
        }
        class NeuralPulse {
            constructor(startNode, endNode) {
                this.startNode = startNode; this.endNode = endNode;
                this.progress = 0; this.speed = 0.025; this.active = true;
            }
            update() {
                if (!this.active) return;
                this.progress += this.speed;
                const connection = connections.find(c => c.a === this.startNode && c.b === this.endNode);
                if(connection) connection.activeIntensity = Math.max(connection.activeIntensity, 1 - this.progress);
                if (this.progress >= 1) { this.endNode.charge += 0.5; this.active = false; }
            }
            draw() {
                if (!this.active) return;
                const x = this.startNode.x + (this.endNode.x - this.startNode.x) * this.progress;
                const y = this.startNode.y + (this.endNode.y - this.startNode.y) * this.progress;
                ctx.beginPath();
                ctx.arc(x, y, 2.5, 0, Math.PI * 2);
                ctx.fillStyle = getComputedStyle(document.documentElement).getPropertyValue('--text-bright');
                ctx.fill();
            }
        }

        function triggerRandomActivity() {
            // The animation runs at about 60fps.
            // 0.5 fires per second (1 fire every 2 seconds) = 0.5/60 = ~0.0083
            if (Math.random() < 0.00003) {
                const inputNodes = nodes.filter(n => n.layer === 0);
                if (inputNodes.length > 0) {
                    inputNodes[Math.floor(Math.random() * inputNodes.length)]?.fire();
                }
            }
        }
        function drawLayerLabels() {
            ctx.font = '12px "Roboto Mono", monospace';
            ctx.fillStyle = 'rgba(136, 146, 176, 0.4)';
            ctx.textAlign = 'center';
            ctx.fillText('Input Layer', canvas.width * 0.1, 30);
            ctx.fillText('Hidden Layer', canvas.width * 0.5, 30);
            ctx.fillText('Output Layer', canvas.width * 0.9, 30);
        }

        document.addEventListener('click', (e) => {
            if (e.target.closest('a, button')) return;
            const rect = canvas.getBoundingClientRect();
            if(rect.top > e.clientY || rect.left > e.clientX || rect.bottom < e.clientY || rect.right < e.clientX) return;

            const clickX = e.clientX - rect.left;
            const clickY = e.clientY - rect.top;
            let layer = (clickX < canvas.width * 0.2) ? 0 : (clickX > canvas.width * 0.8) ? 2 : 1;
            const newNode = new Node(clickX, clickY, layer);
            nodes.push(newNode);

            nodes.forEach(node => {
                if(node !== newNode && node.layer < newNode.layer) {
                    connections.push(new Connection(node, newNode));
                } else if (node !== newNode && node.layer > newNode.layer) {
                    connections.push(new Connection(newNode, node));
                }
            });
            setTimeout(() => newNode.fire(), 100);
        });

        function initNetwork() {
            nodes = [], connections = [], activePulses = [];
            const layerCounts = [5, 8, 4]; // Input, Hidden, Output
            const layerXPositions = [0.1, 0.5, 0.9];
            
            for(let l = 0; l < layerCounts.length; l++) {
                const numNodes = layerCounts[l];
                for (let i = 0; i < numNodes; i++) {
                    const x = canvas.width * layerXPositions[l] + (Math.random() - 0.5) * 50;
                    const y = canvas.height * (i + 1) / (numNodes + 1);
                    nodes.push(new Node(x, y, l));
                }
            }
            
            for(let i = 0; i < nodes.length; i++) {
                for(let j = 0; j < nodes.length; j++) {
                    if (nodes[i].layer === nodes[j].layer - 1) {
                        connections.push(new Connection(nodes[i], nodes[j]));
                    }
                }
            }
        }

        function animateNetwork() {
            requestAnimationFrame(animateNetwork);
            if (canvas.classList.contains('hidden')) return;
            ctx.clearRect(0, 0, canvas.width, canvas.height);
            drawLayerLabels();
            triggerRandomActivity();
            connections.forEach(c => { c.update(); c.draw(); });
            nodes.forEach(n => { n.update(); n.draw(); });
            activePulses = activePulses.filter(p => { p.update(); p.draw(); return p.active; });
        }
        
        function resizeCanvas() { canvas.width = window.innerWidth; canvas.height = window.innerHeight; initNetwork(); }
        window.addEventListener('resize', resizeCanvas);
        document.addEventListener('DOMContentLoaded', () => { resizeCanvas(); setTimeout(animateNetwork, 100); });
    </script>
</body>
</html>